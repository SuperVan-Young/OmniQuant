{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "import os\n",
    "\n",
    "MODEL_DIR = '/home/xuechenhao/hugginface'\n",
    "\n",
    "config_list = {\n",
    "    \"llama-7b-meta\": 'llama7b',\n",
    "    \"llama-13b-meta\": 'llama13b',\n",
    "    \"llama-30b-meta\": 'llama30b',\n",
    "    \"llama-65b-meta\": 'llama65b',\n",
    "    \"opt-6.7b\": 'opt6b',\n",
    "    \"opt-13b\": 'opt13b',\n",
    "    \"opt-30b\": 'opt30b',\n",
    "    \"opt-66b\": 'opt66b',\n",
    "}\n",
    "\n",
    "def generate_sim_workload(config_name):\n",
    "    config_path = os.path.join(MODEL_DIR, config_name)\n",
    "    config = AutoConfig.from_pretrained(config_path)\n",
    "\n",
    "    # print(config)\n",
    "    # print(config_name)\n",
    "\n",
    "    h = config.hidden_size\n",
    "    L = config.num_hidden_layers\n",
    "    head = config.num_attention_heads\n",
    "    S = config.max_position_embeddings\n",
    "\n",
    "    # they only count linear in olive, so do we\n",
    "    # s, in; out, in; s, out\n",
    "    qkvproj = [ [S, h], [h*3, h], [S, h*3], [], [], 4, 1,]\n",
    "    oproj = [ [S, h], [h, h], [S, h], [], [], 4, 1,]\n",
    "    if 'llama' in config_name:\n",
    "        h_ = config.intermediate_size\n",
    "        fc1 = [ [S, h], [2*h_, h], [S, 2*h_], [], [], 4, 1,]\n",
    "    else:\n",
    "        h_ = config.ffn_dim\n",
    "        fc1 = [ [S, h], [h_, h], [S, h_], [], [], 4, 1,]\n",
    "    fc2 = [ [S, h_], [h, h_], [S, h], [], [], 4, 1,]\n",
    "    \n",
    "    workload = []\n",
    "\n",
    "    for _ in range(1):\n",
    "    # for _ in range(L):\n",
    "        workload.append(qkvproj)\n",
    "        workload.append(oproj)\n",
    "        workload.append(fc1)\n",
    "        workload.append(fc2)\n",
    "\n",
    "    # print workload op by op\n",
    "    print(f\"{config_list[config_name]} = [\")\n",
    "    for op in workload:\n",
    "        print(op, \",\")\n",
    "    print(']\\n')\n",
    "    \n",
    "\n",
    "    return workload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama7b = [\n",
      "[[2048, 4096], [12288, 4096], [2048, 12288], [], [], 4, 1] ,\n",
      "[[2048, 4096], [4096, 4096], [2048, 4096], [], [], 4, 1] ,\n",
      "[[2048, 4096], [22016, 4096], [2048, 22016], [], [], 4, 1] ,\n",
      "[[2048, 11008], [4096, 11008], [2048, 4096], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "llama13b = [\n",
      "[[2048, 5120], [15360, 5120], [2048, 15360], [], [], 4, 1] ,\n",
      "[[2048, 5120], [5120, 5120], [2048, 5120], [], [], 4, 1] ,\n",
      "[[2048, 5120], [27648, 5120], [2048, 27648], [], [], 4, 1] ,\n",
      "[[2048, 13824], [5120, 13824], [2048, 5120], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "llama30b = [\n",
      "[[2048, 6656], [19968, 6656], [2048, 19968], [], [], 4, 1] ,\n",
      "[[2048, 6656], [6656, 6656], [2048, 6656], [], [], 4, 1] ,\n",
      "[[2048, 6656], [35840, 6656], [2048, 35840], [], [], 4, 1] ,\n",
      "[[2048, 17920], [6656, 17920], [2048, 6656], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "llama65b = [\n",
      "[[2048, 8192], [24576, 8192], [2048, 24576], [], [], 4, 1] ,\n",
      "[[2048, 8192], [8192, 8192], [2048, 8192], [], [], 4, 1] ,\n",
      "[[2048, 8192], [44032, 8192], [2048, 44032], [], [], 4, 1] ,\n",
      "[[2048, 22016], [8192, 22016], [2048, 8192], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "opt6b = [\n",
      "[[2048, 4096], [12288, 4096], [2048, 12288], [], [], 4, 1] ,\n",
      "[[2048, 4096], [4096, 4096], [2048, 4096], [], [], 4, 1] ,\n",
      "[[2048, 4096], [16384, 4096], [2048, 16384], [], [], 4, 1] ,\n",
      "[[2048, 16384], [4096, 16384], [2048, 4096], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "opt13b = [\n",
      "[[2048, 5120], [15360, 5120], [2048, 15360], [], [], 4, 1] ,\n",
      "[[2048, 5120], [5120, 5120], [2048, 5120], [], [], 4, 1] ,\n",
      "[[2048, 5120], [20480, 5120], [2048, 20480], [], [], 4, 1] ,\n",
      "[[2048, 20480], [5120, 20480], [2048, 5120], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "opt30b = [\n",
      "[[2048, 7168], [21504, 7168], [2048, 21504], [], [], 4, 1] ,\n",
      "[[2048, 7168], [7168, 7168], [2048, 7168], [], [], 4, 1] ,\n",
      "[[2048, 7168], [28672, 7168], [2048, 28672], [], [], 4, 1] ,\n",
      "[[2048, 28672], [7168, 28672], [2048, 7168], [], [], 4, 1] ,\n",
      "]\n",
      "\n",
      "opt66b = [\n",
      "[[2048, 9216], [27648, 9216], [2048, 27648], [], [], 4, 1] ,\n",
      "[[2048, 9216], [9216, 9216], [2048, 9216], [], [], 4, 1] ,\n",
      "[[2048, 9216], [36864, 9216], [2048, 36864], [], [], 4, 1] ,\n",
      "[[2048, 36864], [9216, 36864], [2048, 9216], [], [], 4, 1] ,\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for config_name in config_list:\n",
    "    generate_sim_workload(config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
