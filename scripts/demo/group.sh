#!/bin/bash

# This script is generated by generate_scripts.py.
# This script is exptected to be run on server V100.

MODEL_DIR=/home/xuechenhao/hugginface
OUTPUT_DIR=./output_static_demo

# fc2_W16A4_g128
mkdir -p $OUTPUT_DIR/fc2_W16A4_g128/opt-6.7b
CUDA_VISIBLE_DEVICES="0" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/opt-6.7b \
--output_dir $OUTPUT_DIR/fc2_W16A4_g128/opt-6.7b \
--wbits 16 \
--abits 4 \
--aow-quant-act-fc2 \
--act-group-size 128 \
--eval-ppl-dataset wikitext2 \
&

# fc2_W16A4_g128_ol1p128
mkdir -p $OUTPUT_DIR/fc2_W16A4_g128_ol1p128/opt-6.7b
CUDA_VISIBLE_DEVICES="1" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/opt-6.7b \
--output_dir $OUTPUT_DIR/fc2_W16A4_g128_ol1p128/opt-6.7b \
--wbits 16 \
--abits 4 \
--aow-quant-act-fc2 \
--act-group-size 128 \
--act-outlier-ratio 0.0078125 \
--eval-ppl-dataset wikitext2 \
&

# oproj_W16A4_g128
mkdir -p $OUTPUT_DIR/oproj_W16A4_g128/opt-6.7b
CUDA_VISIBLE_DEVICES="2" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/opt-6.7b \
--output_dir $OUTPUT_DIR/oproj_W16A4_g128/opt-6.7b \
--wbits 16 \
--abits 4 \
--aow-quant-act-oproj \
--act-group-size 128 \
--eval-ppl-dataset wikitext2 \
&

# oproj_W16A4_g128_ol1p128
mkdir -p $OUTPUT_DIR/oproj_W16A4_g128_ol1p128/opt-6.7b
CUDA_VISIBLE_DEVICES="3" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/opt-6.7b \
--output_dir $OUTPUT_DIR/oproj_W16A4_g128_ol1p128/opt-6.7b \
--wbits 16 \
--abits 4 \
--aow-quant-act-oproj \
--act-group-size 128 \
--act-outlier-ratio 0.0078125 \
--eval-ppl-dataset wikitext2 \
&

# fc2_W16A4_g128
mkdir -p $OUTPUT_DIR/fc2_W16A4_g128/llama-7b-meta
CUDA_VISIBLE_DEVICES="4" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/llama-7b-meta \
--output_dir $OUTPUT_DIR/fc2_W16A4_g128/llama-7b-meta \
--wbits 16 \
--abits 4 \
--aow-quant-act-fc2 \
--act-group-size 128 \
--eval-ppl-dataset wikitext2 \
&

# fc2_W16A4_g128_ol1p128
mkdir -p $OUTPUT_DIR/fc2_W16A4_g128_ol1p128/llama-7b-meta
CUDA_VISIBLE_DEVICES="5" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/llama-7b-meta \
--output_dir $OUTPUT_DIR/fc2_W16A4_g128_ol1p128/llama-7b-meta \
--wbits 16 \
--abits 4 \
--aow-quant-act-fc2 \
--act-group-size 128 \
--act-outlier-ratio 0.0078125 \
--eval-ppl-dataset wikitext2 \
&

# oproj_W16A4_g128
mkdir -p $OUTPUT_DIR/oproj_W16A4_g128/llama-7b-meta
CUDA_VISIBLE_DEVICES="6" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/llama-7b-meta \
--output_dir $OUTPUT_DIR/oproj_W16A4_g128/llama-7b-meta \
--wbits 16 \
--abits 4 \
--aow-quant-act-oproj \
--act-group-size 128 \
--eval-ppl-dataset wikitext2 \
&

# oproj_W16A4_g128_ol1p128
mkdir -p $OUTPUT_DIR/oproj_W16A4_g128_ol1p128/llama-7b-meta
CUDA_VISIBLE_DEVICES="7" python main.py \
--eval_ppl --epoch 0 --quant-method aowquant \
--model $MODEL_DIR/llama-7b-meta \
--output_dir $OUTPUT_DIR/oproj_W16A4_g128_ol1p128/llama-7b-meta \
--wbits 16 \
--abits 4 \
--aow-quant-act-oproj \
--act-group-size 128 \
--act-outlier-ratio 0.0078125 \
--eval-ppl-dataset wikitext2 \
&
wait

